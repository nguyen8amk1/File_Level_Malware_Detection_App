# TODO
New Benign Dataset: https://zenodo.org/records/4559436 [] @Next
    https://www.kaggle.com/datasets/dheemanthbhat/microsoft-malware-sample

New Clean doc dataset: 
    We Generate it ourselves [] 

Bug: 
    Batch size greater than 1 not working (2h) [] 

Validate the model [] (4h) @ThuongJob 
Adjust the model [] (2h) @ThuongJob

Make the front end looks good [] () 
    1. Have a better upload file form [X] 
    2. Have a loading [X] 
    3. Have a pop up to show the result [] @Current

(Optional) Wrap the web app in docker ?? @Later


# DONE
+ Make the full model [X] () 
    1. Cut the Malconv into 2 parts 
        1. the Ms - convolution part [X] (1h) 
            NOTE: Test make sure it works 
        2. the Mf - classification part  [X] () 
            NOTE: Test make sure it works 

        -> Then connect them together just like normal :v [X]

    2. Add the f aggregate function [X] () 
        the average function
        takes n 128 dim input -> 1 128 dim output  [X]

        + Problem: 
            We have to change the data loader format [] (1h) 
                Into an array of streams 

Understand how the data works
Make our data work with the model 

+ Process each file into a csv file [X] (1h)
    write a shellscript for that 

    + What really i want as the input of the model:
        we need a file label along with the streams labels [] 
            file name + benign/normal
        The dataset seperation is kinda wrong :v 

        -> have a separate summary files csv, that contains the file labels
        -> have a file csv, that contains the stream labels
        FileLevelModel Input x: a single file (meaning: ...)
        FileLevelModel Output a boolean value (benign, or normal)

        each file's streams contain in a csv file
        name of the csv file is the name of the ole files

        1. Keep the some columns [] 
        1. name
        2. stream label
        3. stream data from n to m
        2.

Put the test code into the oletrain [X] 
Split the train and test files [X]

using olefile
Get the file then parse it into streams [X]
save the streams to a csv [X] 

Make the model take abitrary input [] 
    -> Cut and shape it to 1018 length [X]
Save the model and use it to check files [X]

Write the file parser backend in Flask: [X] 
    Write a simple flask hello world api []
    What api do we need: 
        an checkfilemalware api 
            request: upload a file 
            response: a boolean
            
    send a file through curl then return a result 

Write the file parser front end [X] () 
    Using flask as well =))
    input file 
    show result 
