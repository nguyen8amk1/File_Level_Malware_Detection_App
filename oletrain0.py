# coding: utf-8
import os
import time
import sys
import yaml
import csv 
import numpy as np
import pandas as pd
from src.util import FileLevelOLEDataset, OLEDataset, ExeDataset,write_pred
from src.model import MalConv, FileLevelModel
from torch.utils.data import DataLoader
from sklearn.metrics import precision_score, recall_score, f1_score
import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable


# Load config file for experiment
try:
    config_path = sys.argv[1]
    seed = int(sys.argv[2])
    conf = yaml.load(open(config_path,'r'))
except:
    print('Usage: python3 run_exp.py <config file path> <seed>')
    sys.exit()


exp_name = conf['exp_name']+'_sd_'+str(seed)
print('Experiment:')
print('\t',exp_name)

np.random.seed(seed)
torch.manual_seed(seed)

## NOTE: VALIDATION DATA
## the index is epochs, the elements is the loss value 
# file_level_lossPlot_train = []
# file_level_lossPlot_validation = []
#
# figure3_train_csv = "./validation_csvs/figure3_train.csv"
# figure3_validation_csv = "./validation_csvs/figure3_validation.csv"
# figure3_fields = ["Epoch", "Loss"]
#
# malconv_precision_malware = 0
# malconv_precision_normal = 0
# malconv_recall_malware = 0
# malconv_recall_normal = 0
# malconv_f1_malware = 0
# malconv_f1_normal = 0
#
# file_level_precision_malware = 0
# file_level_precision_normal = 0
# file_level_recall_malware = 0
# file_level_recall_normal = 0
# file_level_f1_malware = 0
# file_level_f1_normal = 0
#
# table3_csv = "./validation_csvs/table3.csv"
# table_3_fields = ['Model Name', 'Precision Malware', 'Precision Normal', 'Recall Malware', 'Recall Normal', 'F1 Malware', 'F1 Normal']


# file_level_fmin_precision_malware = 0
# file_level_fmin_precision_normal = 0
# file_level_fmin_recall_malware = 0
# file_level_fmin_recall_normal = 0
# file_level_fmin_f1_malware = 0
# file_level_fmin_f1_normal = 0
#
# file_level_fmax_precision_malware = 0
# file_level_fmax_precision_normal = 0
# file_level_fmax_recall_malware = 0
# file_level_fmax_recall_normal = 0
# file_level_fmax_f1_malware = 0
# file_level_fmax_f1_normal = 0
#
# file_level_favg_precision_malware = 0
# file_level_favg_precision_normal = 0
# file_level_favg_recall_malware = 0
# file_level_favg_recall_normal = 0
# file_level_favg_f1_malware = 0
# file_level_favg_f1_normal = 0
#
# table_4_fields = ['Model Name', 'Precision Malware', 'Precision Normal', 'Recall Malware', 'Recall Normal', 'F1 Malware', 'F1 Normal']
# table_4_csv = "./validation_csvs/table4.csv"

def figure3_entry(epoch, loss): 
    return {figure3_fields[0]: epoch, figure3_fields[1]: loss} 

def table3_entry(modelname, precision_malware, precision_normal, recall_malware, recall_normal, f1_malware, f1_normal): 
    return {table_3_fields[0]: modelname, 
            table_3_fields[1]: precision_malware, 
            table_3_fields[2]: precision_normal, 
            table_3_fields[3]: recall_malware, 
            table_3_fields[4]: recall_normal, 
            table_3_fields[5]: f1_malware, 
            table_3_fields[6]: f1_normal} 

def table_4_entry(modelname, precision_malware, precision_normal, recall_malware, recall_normal, f1_malware, f1_normal):
    return {table_4_fields[0]: modelname, 
            table_4_fields[1]: precision_malware, 
            table_4_fields[2]: precision_normal, 
            table_4_fields[3]: recall_malware, 
            table_4_fields[4]: recall_normal, 
            table_4_fields[5]: f1_malware, 
            table_4_fields[6]: f1_normal} 

def write_csv_file(filename, fields, mydict): 
# writing to csv file
    with open(filename, 'w') as csvfile:
        # creating a csv dict writer object
        writer = csv.DictWriter(csvfile, fieldnames=fields)
    
        # writing headers (field names)
        writer.writeheader()
    
        # writing data rows
        writer.writerows(mydict)

def write_validation_data(): 
    print(file_level_lossPlot_train)
    print(file_level_lossPlot_validation)
    print(file_level_precision_malware)
    print(file_level_precision_normal)
    print(file_level_recall_malware)
    print(file_level_recall_normal)
    print(file_level_f1_malware)
    print(file_level_f1_normal)
    # write_csv_file(figure3_train_csv, figure3_fields, figure3_entries);
    # write_csv_file(figure3_validation_csv, figure3_fields, figure3_entries);


modelIndex = 0 
model_names = ["MalConv", "FileLevel"]




# TODO: the model index should start at 0 then increment to 1 in a for loop
# vd: for modelIndex in range(0, 2): 

log_dir = conf['log_dir']
pred_dir = conf['pred_dir']
checkpoint_dir = conf['checkpoint_dir']


log_file_path = log_dir+exp_name+'.log'
chkpt_acc_path = checkpoint_dir+exp_name+'.model'
pred_path = pred_dir+exp_name+'.pred'

# Parameters
use_gpu = conf['use_gpu']
use_cpu = conf['use_cpu']
learning_rate = conf['learning_rate']
max_step = conf['max_step']
test_step = conf['test_step']
batch_size = conf['batch_size']
first_n_byte = conf['first_n_byte']
window_size = conf['window_size']
display_step = conf['display_step']

sample_cnt = conf['sample_cnt']


# TODO: generate a dataloader that looks similar to this dataloader and everything will works nicely :v 
# Should just:
# 1. Change the config 
# 2. Swap out the ExeDataset with our OLEDataSet, then it should just works 

# dataloader = DataLoader(ExeDataset(list(tr_table.index), train_data_path, list(tr_table.ground_truth),first_n_byte),
#                             batch_size=batch_size, shuffle=True, num_workers=use_cpu)
# validloader = DataLoader(ExeDataset(list(val_table.index), valid_data_path, list(val_table.ground_truth),first_n_byte),
#                         batch_size=batch_size, shuffle=False, num_workers=use_cpu)

# TODO: Figure out a way to separate the train and test dataset 
# train_dataset = "./train_dataset.csv" 
# test_dataset = "./test_dataset.csv"
# dataloader = DataLoader(OLEDataset(train_dataset))
# validloader = DataLoader(OLEDataset(test_dataset))
batch_size = None
train_dataset = None
test_dataset = None
dataloader = None
validLoader = None
malconv = None







if(model_names[modelIndex] == "MalConv"): 
    batch_size = 1 
    train_dataset = OLEDataset("./oledata/train/file_status_stream.csv")
    test_dataset = OLEDataset("./oledata/test/file_status_stream.csv")
    dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    validloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    malconv = MalConv(input_length=first_n_byte,window_size=window_size)
    #malconv = FileLevelModel(input_length=first_n_byte,window_size=window_size)
else: 
    batch_size = 1 
# train_dataset = FileLevelOLEDataset("./oledata", "./oledata/train", "shuffled_file_status.csv")
# test_dataset = FileLevelOLEDataset("./oledata", "./oledata/test", "shuffled_file_status.csv")
# train_dataset = FileLevelOLEDataset("./oledata", "./oledata/train", "file_status.csv")
# test_dataset = FileLevelOLEDataset("./oledata", "./oledata/test", "file_status.csv")
    train_dataset = FileLevelOLEDataset("./oledata", "./oledata/train", "file_status_original.csv")
    test_dataset = FileLevelOLEDataset("./oledata", "./oledata/test", "file_status_original.csv")
# train_dataset = FileLevelOLEDataset("./oledata", "./oledata/train", "file_status_new_only.csv")
# test_dataset = FileLevelOLEDataset("./oledata", "./oledata/test", "file_status_new_only.csv")
# train_dataset = FileLevelOLEDataset("./oledata", "./oledata/train", "file_status_test.csv")
# test_dataset = FileLevelOLEDataset("./oledata", "./oledata/test", "file_status_test.csv")
# train_dataset = FileLevelOLEDataset("./oledata", "./oledata/train", "shuffled_file_status_test.csv")
# test_dataset = FileLevelOLEDataset("./oledata", "./oledata/test", "shuffled_file_status_test.csv")
    dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
#dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    validloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

# first_data = train_dataset[0]
# features, labels = first_data
# input_size = len(features)
# print(f"Input size: {input_size}")
# print("First feature and label")
# print(features, labels)
# print()


#malconv = MalConv(input_length=first_n_byte,window_size=window_size)
    malconv = FileLevelModel(input_length=first_n_byte,window_size=window_size)



bce_loss = nn.BCEWithLogitsLoss()
adam_optim = optim.Adam([{'params':malconv.parameters()}],lr=learning_rate)
sigmoid = nn.Sigmoid()

if use_gpu:
    malconv = malconv.cuda()
    bce_loss = bce_loss.cuda()
    sigmoid = sigmoid.cuda()
    sigmoid = sigmoid.cuda()

step_msg = 'step-{}-loss-{:.6f}-acc-{:.4f}-time-{:.2f}'
valid_msg = 'step-{}-tr_loss-{:.6f}-tr_acc-{:.4f}-val_loss-{:.6f}-val_acc-{:.4f}'
log_msg = '{}, {:.6f}, {:.4f}, {:.6f}, {:.4f}, {:.2f}'
history = {}
history['tr_loss'] = []
history['tr_acc'] = []

history['val_precision'] = []
history['val_recall'] = []
history['val_f1'] = []

history['tr_precision'] = []
history['tr_recall'] = []
history['tr_f1'] = []
    

log = open(log_file_path,'w')
log.write('step,tr_loss, tr_acc, val_loss, val_acc, time\n')

valid_best_acc = 0.0
total_step = 0
step_cost_time = 0


'''
while total_step < max_step:
    
    #print("TRAINING")
    # Training 
    for step,batch_data in enumerate(dataloader):
        start = time.time()
        
        adam_optim.zero_grad()
        
        cur_batch_size = batch_data[0].size(0)

        exe_input = batch_data[0].cuda() if use_gpu else batch_data[0]
        exe_input = Variable(exe_input.long(),requires_grad=False)
        
        label = batch_data[1].cuda() if use_gpu else batch_data[1]
        label = Variable(label.float(),requires_grad=False)
        
        pred = malconv(exe_input)
        # print(f"Prediction: {pred}, Label: {label}")
        #print(f"Y predicted: {pred}, Label: {label}")
        loss = bce_loss(pred,label)
        loss.backward()
        adam_optim.step()


        pred_np = sigmoid(pred).cpu().data.numpy()
        label_np = label.cpu().data.numpy()
        pred_binary = (pred_np >= 0.5).astype(int)
        
        history['tr_loss'].append(loss.cpu().data.numpy().item())
        history['tr_acc'].extend(list(label.cpu().data.numpy().astype(int)==(sigmoid(pred).cpu().data.numpy()+0.5).astype(int)))
        history['tr_precision'].append(precision_score(label_np, pred_binary, zero_division=0))
        history['tr_recall'].append(recall_score(label_np, pred_binary, zero_division=0))
        history['tr_f1'].append(f1_score(label_np, pred_binary, zero_division=0))
        
        step_cost_time = time.time()-start
        
        if (step+1)%display_step == 0:
            print(step_msg.format(total_step,np.mean(history['tr_loss']),
                                  np.mean(history['tr_acc']),step_cost_time),end='\r',flush=True)

            file_level_lossPlot_train.append(np.mean(history['tr_loss']))
        total_step += 1

        # Interupt for validation
        if total_step%test_step ==0:
            break
    
    
    # Testing
    history['val_loss'] = []
    history['val_acc'] = []
    history['val_pred'] = []
    history['val_precision'] = []
    history['val_recall'] = []
    history['val_f1'] = []
    
    #print("TESTING")
    for _,val_batch_data in enumerate(validloader):
        cur_batch_size = val_batch_data[0].size(0)

        exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]
        exe_input = Variable(exe_input.long(),requires_grad=False)

        label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]
        label = Variable(label.float(),requires_grad=False)

        pred = malconv(exe_input)
        # print(f"Prediction: {pred}, Label: {label}")
        loss = bce_loss(pred,label)

        pred_np = sigmoid(pred).cpu().data.numpy()
        label_np = label.cpu().data.numpy()
        pred_binary = (pred_np >= 0.5).astype(int)

        history['val_loss'].append(loss.cpu().data.numpy().item())
        history['val_acc'].extend(list(label.cpu().data.numpy().astype(int)==(sigmoid(pred).cpu().data.numpy()+0.5).astype(int)))
        history['val_pred'].append(list(sigmoid(pred).cpu().data.numpy()))
        history['val_precision'].append(precision_score(label_np, pred_binary, zero_division=0))
        history['val_recall'].append(recall_score(label_np, pred_binary, zero_division=0))
        history['val_f1'].append(f1_score(label_np, pred_binary, zero_division=0))

    print(log_msg.format(total_step, np.mean(history['tr_loss']), np.mean(history['tr_acc']),
                    np.mean(history['val_loss']), np.mean(history['val_acc']),step_cost_time),
          file=log,flush=True)
    
    print(valid_msg.format(total_step,np.mean(history['tr_loss']),np.mean(history['tr_acc']),
                           np.mean(history['val_loss']),np.mean(history['val_acc'])))

    file_level_lossPlot_validation.append(np.mean(history['val_loss']))

    if valid_best_acc < np.mean(history['val_acc']):
        valid_best_acc = np.mean(history['val_acc'])
        torch.save(malconv,chkpt_acc_path)
        # print('Checkpoint saved at',chkpt_acc_path)
        # #write_pred(history['val_pred'],valid_idx,pred_path)
        # print('Prediction saved at', pred_path)

    history['tr_loss'] = []
    history['tr_acc'] = []

# TODO: Save the model
torch.save(malconv.state_dict(), './ole_model.pth')

file_level_precision_malware = np.mean([p[1] for p in history['val_precision']])
file_level_precision_normal = np.mean([p[0] for p in history['val_precision']])
file_level_recall_malware = np.mean([r[1] for r in history['val_recall']])
file_level_recall_normal = np.mean([r[0] for r in history['val_recall']])
file_level_f1_malware = np.mean([f[1] for f in history['val_f1']])
file_level_f1_normal = np.mean([f[0] for f in history['val_f1']])

write_validation_data()


'''



while total_step < max_step:
    # Training 
    for step, batch_data in enumerate(dataloader):
        start = time.time()
        adam_optim.zero_grad()
        
        cur_batch_size = batch_data[0].size(0)
        exe_input = batch_data[0].cuda() if use_gpu else batch_data[0]
        exe_input = Variable(exe_input.long(), requires_grad=False)
        label = batch_data[1].cuda() if use_gpu else batch_data[1]
        label = Variable(label.float(), requires_grad=False)
        
        pred = malconv(exe_input)
        loss = bce_loss(pred, label)
        loss.backward()
        adam_optim.step()
        
        pred_np = sigmoid(pred).cpu().data.numpy()
        label_np = label.cpu().data.numpy()
        pred_binary = (pred_np >= 0.5).astype(int)
        
        history['tr_loss'].append(loss.cpu().data.numpy().item())
        history['tr_acc'].extend(list(label_np == pred_binary))
        
        precision = precision_score(label_np, pred_binary, average=None, zero_division=0)
        recall = recall_score(label_np, pred_binary, average=None, zero_division=0)
        f1 = f1_score(label_np, pred_binary, average=None, zero_division=0)
        
        if len(precision) == 1:  # If only one class is present
            if 1 in label_np:
                precision = [0, precision[0]]
                recall = [0, recall[0]]
                f1 = [0, f1[0]]
            else:
                precision = [precision[0], 0]
                recall = [recall[0], 0]
                f1 = [f1[0], 0]
        
        history['tr_precision'].append(precision)
        history['tr_recall'].append(recall)
        history['tr_f1'].append(f1)
        
        step_cost_time = time.time() - start
        
        if (step + 1) % display_step == 0:
            print(step_msg.format(total_step, np.mean(history['tr_loss']),
                                  np.mean(history['tr_acc']), step_cost_time), end='\r', flush=True)

        
        total_step += 1

        # Interrupt for validation
        if total_step % test_step == 0:
            break
    
    file_level_lossPlot_train.append({"Epoch": total_step, "Loss": np.mean(history['tr_loss'])})
    # Validation
    history['val_loss'] = []
    history['val_acc'] = []
    history['val_precision'] = []
    history['val_recall'] = []
    history['val_f1'] = []
    
    for _, val_batch_data in enumerate(validloader):
        exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]
        exe_input = Variable(exe_input.long(), requires_grad=False)
        label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]
        label = Variable(label.float(), requires_grad=False)
        
        pred = malconv(exe_input)
        loss = bce_loss(pred, label)
        
        pred_np = sigmoid(pred).cpu().data.numpy()
        label_np = label.cpu().data.numpy()
        pred_binary = (pred_np >= 0.5).astype(int)
        
        history['val_loss'].append(loss.cpu().data.numpy().item())
        history['val_acc'].extend(list(label_np == pred_binary))
        
        precision = precision_score(label_np, pred_binary, average=None, zero_division=0)
        recall = recall_score(label_np, pred_binary, average=None, zero_division=0)
        f1 = f1_score(label_np, pred_binary, average=None, zero_division=0)
        
        if len(precision) == 1:  # If only one class is present
            if 1 in label_np:
                precision = [0, precision[0]]
                recall = [0, recall[0]]
                f1 = [0, f1[0]]
            else:
                precision = [precision[0], 0]
                recall = [recall[0], 0]
                f1 = [f1[0], 0]
        
        history['val_precision'].append(precision)
        history['val_recall'].append(recall)
        history['val_f1'].append(f1)

    file_level_lossPlot_validation.append({"Epoch": total_step, "Loss": np.mean(history['val_loss'])})
    
    # Store precision, recall, and F1 scores for each class
    file_level_precision_malware = np.mean([p[1] for p in history['tr_precision']])
    file_level_precision_normal = np.mean([p[0] for p in history['tr_precision']])
    file_level_recall_malware = np.mean([r[1] for r in history['tr_recall']])
    file_level_recall_normal = np.mean([r[0] for r in history['tr_recall']])
    file_level_f1_malware = np.mean([f[1] for f in history['tr_f1']])
    file_level_f1_normal = np.mean([f[0] for f in history['tr_f1']])

    val_precision_malware = np.mean([p[1] for p in history['val_precision']])
    val_precision_normal = np.mean([p[0] for p in history['val_precision']])
    val_recall_malware = np.mean([r[1] for r in history['val_recall']])
    val_recall_normal = np.mean([r[0] for r in history['val_recall']])
    val_f1_malware = np.mean([f[1] for f in history['val_f1']])
    val_f1_normal = np.mean([f[0] for f in history['val_f1']])

    print(log_msg.format(total_step, np.mean(history['tr_loss']), np.mean(history['tr_acc']),
                         np.mean(history['val_loss']), np.mean(history['val_acc']), step_cost_time),
          file=log, flush=True)
    
    print(valid_msg.format(total_step, np.mean(history['tr_loss']), np.mean(history['tr_acc']),
                           np.mean(history['val_loss']), np.mean(history['val_acc'])))

    if valid_best_acc < np.mean(history['val_acc']):
        valid_best_acc = np.mean(history['val_acc'])
        torch.save(malconv, chkpt_acc_path)

    history['tr_loss'] = []
    history['tr_acc'] = []

torch.save(malconv.state_dict(), './ole_model.pth')
write_validation_data()

# Print or log the metrics after each epoch
print(f'Training Precision (Malware): {file_level_precision_malware:.4f}')
print(f'Training Precision (Normal): {file_level_precision_normal:.4f}')
print(f'Training Recall (Malware): {file_level_recall_malware:.4f}')
print(f'Training Recall (Normal): {file_level_recall_normal:.4f}')
print(f'Training F1 (Malware): {file_level_f1_malware:.4f}')
print(f'Training F1 (Normal): {file_level_f1_normal:.4f}')

print(f'Validation Precision (Malware): {val_precision_malware:.4f}')
print(f'Validation Precision (Normal): {val_precision_normal:.4f}')
print(f'Validation Recall (Malware): {val_recall_malware:.4f}')
print(f'Validation Recall (Normal): {val_recall_normal:.4f}')
print(f'Validation F1 (Malware): {val_f1_malware:.4f}')
print(f'Validation F1 (Normal): {val_f1_normal:.4f}')
